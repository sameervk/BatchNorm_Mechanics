{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Successfully implemented the calculation of Batch Normalization. \n",
    "\n",
    "> 2. Written in tensorflow and executed using Keras Layers.\n",
    "\n",
    "> 3. Tested on MNIST dataset. \n",
    "\n",
    "> 4. 94% training, validation and test accuracy for 10 epochs.\n",
    "\n",
    "> 5. Results cross-checked by replacing the custom batch norm calculation with the equation using *momentum* \n",
    "     for calculating batch norm as implemented in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * data seems decently balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3,3)\n",
    "ax = ax.flatten()\n",
    "for i,j in enumerate(ax):\n",
    "    \n",
    "    j.imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler_fit = stdscaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = stdscaler_fit.transform(x_train)\n",
    "x_test_scaled = stdscaler_fit.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_scaled.astype(dtype = 'float32', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = x_test_scaled.astype(dtype = 'float32', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244.94693"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.274208"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot_train = tf.keras.utils.to_categorical(y_train, num_classes=10, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "y_onehot_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot_test = tf.keras.utils.to_categorical(y_test, num_classes=10, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random_seed = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled, y_onehot_train = shuffle(x_train_scaled, y_onehot_train, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_scaled = x_train_scaled[:5000]\n",
    "y_onehot_valid =  y_onehot_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_scaled[5000:]\n",
    "y_onehot_train =  y_onehot_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating tf.data.Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_scaled, y_onehot_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_scaled, y_onehot_test))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((x_valid_scaled, y_onehot_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = 60 # used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffersize = len(y_train)\n",
    "buffersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(buffer_size=buffersize, seed=random_seed,\n",
    "                                     reshuffle_each_iteration=True).batch(minibatch, \n",
    "                                                                          drop_remainder = True).prefetch(buffer_size=\n",
    "                                                                                                          tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = valid_dataset.shuffle(buffer_size=buffersize, seed=random_seed, \n",
    "                                      reshuffle_each_iteration=False).batch(batch_size=minibatch).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=buffersize, seed=random_seed, \n",
    "                                      reshuffle_each_iteration=False).batch(batch_size=minibatch).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in test_dataset.take(1):\n",
    "    print(i[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom layers and keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * 3 dense layers followed by 3 batch norm layers and a final dense layer with units equal to number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Custom Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        \n",
    "        super(dense_layer, self).__init__(**kwargs)\n",
    "        self.units =  units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.kernel_weights = self.add_weight(name = 'weights', shape = (input_shape[-1], self.units), \n",
    "                                              dtype = self.dtype, initializer=tf.keras.initializers.Orthogonal(gain=1,seed=random_seed),\n",
    "                                             trainable = self.trainable)\n",
    "        self.bias = self.add_weight(name = 'bias', shape = (self.units,), dtype = self.dtype,\n",
    "                                   initializer=tf.keras.initializers.zeros(), trainable = self.trainable)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return tf.add(tf.matmul(inputs, self.kernel_weights), self.bias)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \n",
    "        config = super(dense_layer, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom BatchNorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custombn_paper(tf.keras.layers.Layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Not implementing momentum as defined in the keras BatchNorm layer\n",
    "    \n",
    "    Population mean and variance are calculated as defined in the paper\n",
    "    \n",
    "    This process can only be used when mini-batch size > 1\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, stateful, **kwargs):\n",
    "        \n",
    "        super(custombn_paper, self).__init__(**kwargs)\n",
    "        \n",
    "        self.stateful = stateful\n",
    "      \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.gamma = self.add_weight(name = 'scale', shape = (1, input_shape[-1]), initializer = tf.keras.initializers.ones(),\n",
    "                                    trainable = self.trainable)\n",
    "        self.beta = self.add_weight(name = 'shift', shape = (1,input_shape[-1]), initializer = tf.keras.initializers.zeros(),\n",
    "                                   trainable = self.trainable)\n",
    "        self.offset = tf.Variable(0.001, dtype = 'float32', trainable=False)\n",
    "        \n",
    "        self.moving_mean = self.add_weight(name = 'moving_mean', shape = (1, input_shape[-1]), initializer = tf.keras.initializers.Zeros(),\n",
    "                                          trainable = False)\n",
    "        self.moving_var =  self.add_weight(name = 'moving_var', shape = (1, input_shape[-1]), initializer = tf.keras.initializers.Zeros(),\n",
    "                                          trainable = False)\n",
    "        \n",
    "        self.batch_count = tf.Variable(0, dtype = 'float32', name = 'batchcount', trainable=False)\n",
    "        \n",
    "        self.batchsize = tf.Variable(2, dtype = 'float32', name='batchsize', trainable=False)\n",
    "\n",
    "        \n",
    "        self.init_mm = self.moving_mean.read_value()\n",
    "        self.init_mv = self.moving_var.read_value()\n",
    "\n",
    "    \n",
    "    def bn_training(self, inputs, axes = [0]):\n",
    "\n",
    "        self.batch_mean, self.batch_var = tf.nn.moments(inputs, axes = axes, keepdims=True)\n",
    "        \n",
    "        self.moving_mean.assign_add(self.batch_mean)\n",
    "        self.moving_var.assign_add(self.batch_var)\n",
    "\n",
    "        return tf.add(tf.multiply(tf.divide(tf.subtract(inputs, self.batch_mean), \n",
    "                                     tf.math.sqrt(tf.add(self.batch_var, self.offset))), self.gamma), self.beta)\n",
    "    \n",
    "\n",
    "    \n",
    "    def update_mm_mv(self):\n",
    "        \"\"\"\n",
    "        Updating mm and mv at the end of epoch\n",
    "        \"\"\"        \n",
    "        self.moving_mean.assign(tf.cond(tf.greater(self.batch_count,0), \n",
    "                                        lambda: tf.divide(self.moving_mean,self.batch_count), lambda: self.moving_mean, name='update_mm'))\n",
    "        \n",
    "        self.moving_var.assign(tf.cond(tf.greater(self.batch_count,0), \n",
    "                                       lambda: tf.multiply(self.moving_var, tf.divide(self.batchsize, tf.multiply(tf.subtract(self.batchsize,1), self.batch_count))),\n",
    "                                       lambda: self.moving_var, name='update_mv'))\n",
    "        \n",
    "    \n",
    "    def bn_inference(self, inputs):\n",
    "        \n",
    "        return tf.add(tf.multiply(tf.divide(tf.subtract(inputs, self.moving_mean), \n",
    "                                     tf.math.sqrt(tf.add(self.moving_var, self.offset))), self.gamma), self.beta)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def reset_states(self):\n",
    "\n",
    "        self.moving_mean.assign(self.init_mm)\n",
    "        self.moving_var.assign(self.init_mv)\n",
    "\n",
    "    def call(self, inputs, training):       \n",
    "        \n",
    "        return tf.cond(tf.equal(training, True, name='train_or_eval'),lambda: self.bn_training(inputs), lambda: self.bn_inference(inputs),\n",
    "                      name = 'call_func') \n",
    "\n",
    "    def get_config(self):\n",
    "        \n",
    "        config = super(custombn_paper, self).get_config()\n",
    "        config.update({'stateful': self.stateful})\n",
    "        \n",
    "        return config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func_bnpaper(inputshape = [1], units1 = 100, units2 =100, units3=100, classes=10):\n",
    "    \n",
    "    input_lyr = tf.keras.Input(shape = inputshape, batch_size=None, name = 'input')\n",
    "    \n",
    "    dense1 = dense_layer(units = units1, name = 'dense1', trainable = True)(input_lyr)\n",
    "    custombn1 = custombn_paper(stateful = True, name = 'bn1', trainable = True)(dense1)     \n",
    "    activation1 = tf.keras.layers.Activation(activation = tf.nn.tanh, name='actv1')(custombn1)\n",
    "    \n",
    "    dense2 = dense_layer(units = units2, name = 'dense2', trainable = True)(activation1)    \n",
    "    custombn2 = custombn_paper(stateful = True, name = 'bn2', trainable = True)(dense2)     \n",
    "    activation2 = tf.keras.layers.Activation(activation = tf.nn.tanh, name='actv2')(custombn2)\n",
    "    \n",
    "    dense3 = dense_layer(units = units3, name = 'dense3', trainable = True)(activation2)    \n",
    "    custombn3 = custombn_paper(stateful = True, name='bn3', trainable = True)(dense3)     \n",
    "    activation3 = tf.keras.layers.Activation(activation = tf.nn.tanh, name='actv3')(custombn3)\n",
    "    \n",
    "    \n",
    "    output_lyr = dense_layer(units = classes, name='output') (activation3)\n",
    "    # no softmax \n",
    "    \n",
    "    return tf.keras.Model(inputs = [input_lyr], outputs = [output_lyr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Callback for resetting moving mean and variances at the end of each epoch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_callback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    \"\"\"\n",
    "    This callback resets the moving mean and variances at the end of each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batchsize, **kwargs):\n",
    "        \n",
    "        super(custom_callback, self).__init__(**kwargs)\n",
    "                \n",
    "        self.batchsize = batchsize\n",
    "        self.batchcount = tf.Variable(0, dtype = tf.int32, trainable=False)\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs =None):\n",
    "        \"\"\"\n",
    "        At the beginning of the training, the batchsize is assigned to\n",
    "        the batchsize variables of the bn layers for correct calc. of \n",
    "        the mm/mv.        \n",
    "        \"\"\"\n",
    "        for layer in self.model.layers:\n",
    "            if layer.__class__.__name__ == 'custombn_paper':\n",
    "                layer.batchsize.assign(self.batchsize)      \n",
    "        \n",
    "    \n",
    "    \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        \"\"\"\n",
    "        This function in combination with functions below\n",
    "        is used to pass the total number of batches in the training data\n",
    "        for the calculation of mm/mv.\n",
    "        \"\"\"\n",
    "        self.batchcount.assign(batch)\n",
    "        tf.cond(tf.equal(self.batchcount,1), self.at_batch_one, self.at_batch_not_one)     \n",
    "        \n",
    "    def at_batch_one(self):\n",
    "        \"\"\"\n",
    "        When the first batch of the training data has been processed \n",
    "        this function retrieves the total batches(steps) and updates\n",
    "        the corresponding variable in the batch norm layers for \n",
    "        calculating moving mean and moving var.                  \n",
    "        \"\"\"\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if layer.__class__.__name__ == 'custombn_paper':\n",
    "\n",
    "                layer.batch_count.assign(self.model.history.params['steps'])\n",
    "\n",
    "        return None\n",
    "        \n",
    "    def at_batch_not_one(self):\n",
    "        tf.cond(tf.equal(self.batchcount, self.model.history.params['steps']-1), self.at_last_batch, self.at_any_batch)\n",
    "    \n",
    "    def at_last_batch(self):\n",
    "        \"\"\"\n",
    "        This layer updates mm/mv after the last batch of the \n",
    "        training data has been processed.        \n",
    "        \"\"\"\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'update_mm_mv'):\n",
    "                layer.update_mm_mv()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def at_any_batch(self):\n",
    "        \"\"\"\n",
    "        Nothing to do any other batch number\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "       \n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        \"\"\"\n",
    "        At the beginning of every epoch, the mm/mv need to be reset to zero.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model.reset_states()       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Callback for saving best model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bnlayer_model = 'cstm_bnlayer_model'\n",
    "\n",
    "if os.path.exists(custom_bnlayer_model):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(custom_bnlayer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_savemodel = tf.keras.callbacks.ModelCheckpoint(os.path.join(custom_bnlayer_model, 'model_{epoch}-{val_loss:.3f}.h5'), mode = 'min',\\\n",
    "                                                 monitor = 'val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Callback for Visualizing in TensorBoard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bnlayer_logs = 'cstm_bnlayer_logs'\n",
    "\n",
    "if os.path.exists(custom_bnlayer_logs):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(custom_bnlayer_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_tb = tf.keras.callbacks.TensorBoard(log_dir = custom_bnlayer_logs, histogram_freq=1, write_graph=True,\\\n",
    "                                        write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.callbacks.TensorBoard at 0x7f6f942eada0>,\n",
       " <tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7f6f942ea7b8>,\n",
       " <__main__.custom_callback at 0x7f6f9430f400>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_list = []\n",
    "cb_list.append([cstm_tb,cb_savemodel, custom_callback(batchsize=60)]) \n",
    "cb_list = cb_list[0]\n",
    "cb_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Adam optimizer has adaptive learning rate feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model using custom defined BN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bnpaper = model_func_bnpaper(inputshape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense1 (dense_layer)         (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "bn1 (custombn_paper)         (None, 100)               403       \n",
      "_________________________________________________________________\n",
      "actv1 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (dense_layer)         (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "bn2 (custombn_paper)         (None, 100)               403       \n",
      "_________________________________________________________________\n",
      "actv2 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense3 (dense_layer)         (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "bn3 (custombn_paper)         (None, 100)               403       \n",
      "_________________________________________________________________\n",
      "actv3 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (dense_layer)         (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 100,919\n",
      "Trainable params: 100,310\n",
      "Non-trainable params: 609\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bnpaper.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bnpaper.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\\\n",
    "                     loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                     metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
    "# If using softmax as the activation of the last layer, then from_logits should be False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs1=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6130 - categorical_accuracy: 0.8245 - val_loss: 0.3467 - val_categorical_accuracy: 0.9017\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.3456 - categorical_accuracy: 0.9018 - val_loss: 0.3170 - val_categorical_accuracy: 0.9100\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3093 - categorical_accuracy: 0.9093 - val_loss: 0.2710 - val_categorical_accuracy: 0.9203\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2579 - categorical_accuracy: 0.9240 - val_loss: 0.2437 - val_categorical_accuracy: 0.9293\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2528 - categorical_accuracy: 0.9257 - val_loss: 0.2375 - val_categorical_accuracy: 0.9307\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2201 - categorical_accuracy: 0.9378 - val_loss: 0.2332 - val_categorical_accuracy: 0.9303\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1934 - categorical_accuracy: 0.9408 - val_loss: 0.2067 - val_categorical_accuracy: 0.9437\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2020 - categorical_accuracy: 0.9408 - val_loss: 0.1988 - val_categorical_accuracy: 0.9420\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1784 - categorical_accuracy: 0.9472 - val_loss: 0.1858 - val_categorical_accuracy: 0.9450\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1782 - categorical_accuracy: 0.9495 - val_loss: 0.1834 - val_categorical_accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "cstm_bnlayer_history1 =  model_bnpaper.fit(train_dataset.take(100), epochs=epochs1, verbose=1, \n",
    "                                           callbacks=cb_list, validation_data=valid_dataset.take(50), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 2ms/step - loss: 0.1842 - categorical_accuracy: 0.9459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18415349675063603, 0.9459]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test dataset\n",
    "model_bnpaper.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_bnpaper\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the custom BN against the method implemented in tensorflow using Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custombn_keras(tf.keras.layers.Layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implementing momentum as defined in the keras BatchNorm layer to calculate\n",
    "    \n",
    "    population mean and variance \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, momentum, stateful, **kwargs):\n",
    "        \n",
    "        super(custombn_keras, self).__init__(**kwargs)\n",
    "        \n",
    "        self.momentum = momentum\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.gamma = self.add_weight(name = 'scale', shape = (1, input_shape[-1]), initializer = tf.keras.initializers.ones(),\n",
    "                                    trainable = self.trainable)\n",
    "        self.beta = self.add_weight(name = 'shift', shape = (1,input_shape[-1]), initializer = tf.keras.initializers.zeros(),\n",
    "                                   trainable = self.trainable)\n",
    "        self.offset = tf.Variable(0.001, dtype = 'float32', trainable=False)\n",
    "        \n",
    "        self.moving_mean = self.add_weight(name = 'moving_mean', shape = (1, input_shape[-1]), initializer = tf.keras.initializers.Zeros(),\n",
    "                                          trainable = False)\n",
    "        self.moving_var =  self.add_weight(name = 'moving_var', shape = (1, input_shape[-1]), initializer = tf.keras.initializers.Zeros(),\n",
    "                                          trainable = False)\n",
    "        \n",
    "        self.init_mm = self.moving_mean.read_value()\n",
    "        self.init_mv = self.moving_var.read_value()\n",
    "        \n",
    "    \n",
    "    def bn_training(self, inputs, axes = [0]):\n",
    "        \n",
    "        \n",
    "        self.batch_mean, self.batch_var = tf.nn.moments(inputs, axes = axes, keepdims=True)\n",
    "        \n",
    "        self.moving_mean.assign((1-self.momentum)*self.moving_mean + self.momentum*self.batch_mean)\n",
    "        # as implemented in tensorflow\n",
    "        self.moving_var.assign((1-self.momentum)*self.moving_var + self.momentum*self.batch_var)\n",
    "        \n",
    "        \n",
    "        return tf.add(tf.multiply(tf.divide(tf.subtract(inputs, self.batch_mean), \n",
    "                                     tf.math.sqrt(tf.add(self.batch_var, self.offset))), self.gamma), self.beta)\n",
    "    \n",
    "    def bn_inference(self, inputs):        \n",
    "        \n",
    "        return tf.add(tf.multiply(tf.divide(tf.subtract(inputs, self.moving_mean), \n",
    "                                     tf.math.sqrt(tf.add(self.moving_var, self.offset))), self.gamma), self.beta)\n",
    "        \n",
    "        \n",
    "    def reset_states(self):\n",
    "        \n",
    "        self.moving_mean.assign(self.init_mm)\n",
    "        self.moving_var.assign(self.init_mv)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training):     \n",
    "        \n",
    "        return tf.cond(tf.equal(training, True),lambda: self.bn_training(inputs), lambda: self.bn_inference(inputs))       \n",
    "    \n",
    "    def get_config(self):\n",
    "        \n",
    "        config = super(custombn_keras, self).get_config()\n",
    "        config.update({'momentum': self.momentum})\n",
    "        \n",
    "        return config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model function using custombn_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_custombn_keras(inputshape = [1], units1 = 100, units2 =100, units3=100, classes=10):\n",
    "    \n",
    "    input_lyr = tf.keras.Input(shape = inputshape, batch_size=None, name = 'input')\n",
    "    \n",
    "    dense1 = dense_layer(units = units1, name = 'dense1', trainable = True)(input_lyr)\n",
    "    custombn1 = custombn_keras(momentum = 0.99, stateful = True, name = 'bn1', trainable = True)(dense1)     \n",
    "    activation1 = tf.keras.layers.Activation(activation = tf.nn.tanh, name='actv1')(custombn1)\n",
    "    \n",
    "    dense2 = dense_layer(units = units2, name = 'dense2', trainable = True)(activation1)    \n",
    "    custombn2 = custombn_keras(momentum = 0.99, stateful = True, name = 'bn2', trainable = True)(dense2)     \n",
    "    activation2 = tf.keras.layers.Activation(activation = tf.nn.tanh, name='actv2')(custombn2)\n",
    "    \n",
    "    dense3 = dense_layer(units = units3, name = 'dense3', trainable = True)(activation2)    \n",
    "    custombn3 = custombn_keras(momentum = 0.99, stateful = True, name='bn3', trainable = True)(dense3)     \n",
    "    activation3 = tf.keras.layers.Activation(activation = tf.nn.tanh, name='actv3')(custombn3)\n",
    "    \n",
    "    \n",
    "    output_lyr = dense_layer(units = classes, name='output') (activation3)\n",
    "    # no softmax \n",
    "    \n",
    "    return tf.keras.Model(inputs = [input_lyr], outputs = [output_lyr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelbn_keras = model_custombn_keras(inputshape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense1 (dense_layer)         (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "bn1 (custombn_keras)         (None, 100)               401       \n",
      "_________________________________________________________________\n",
      "actv1 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (dense_layer)         (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "bn2 (custombn_keras)         (None, 100)               401       \n",
      "_________________________________________________________________\n",
      "actv2 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense3 (dense_layer)         (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "bn3 (custombn_keras)         (None, 100)               401       \n",
      "_________________________________________________________________\n",
      "actv3 (Activation)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (dense_layer)         (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 100,913\n",
      "Trainable params: 100,310\n",
      "Non-trainable params: 603\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelbn_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for layer in modelbn_keras.layers:\n",
    "    print(layer.stateful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelbn_keras.stateful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custombn_keras_callbck(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    For resetting mm/mv after each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super(custombn_keras_callbck, self).__init__(**kwargs)\n",
    "            \n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        \n",
    "        self.model.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bnkeras_svdmodel = 'cstm_bnkeras_svdmodel'\n",
    "\n",
    "if os.path.exists(custom_bnkeras_svdmodel):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(custom_bnkeras_svdmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_savemodel = tf.keras.callbacks.ModelCheckpoint(os.path.join(custom_bnkeras_svdmodel, 'model_{epoch}-{val_loss:.3f}.h5'), mode = 'min',\\\n",
    "                                                 monitor = 'val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bnkeras_logs = 'cstm_bnkeras_logs'\n",
    "\n",
    "if os.path.exists(custom_bnkeras_logs):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(custom_bnkeras_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstm_tb = tf.keras.callbacks.TensorBoard(log_dir = custom_bnkeras_logs, histogram_freq=1, write_graph=True,\\\n",
    "                                        write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.callbacks.TensorBoard at 0x7f6f413d05f8>,\n",
       " <tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7f6f413d0518>,\n",
       " <__main__.custombn_keras_callbck at 0x7f6f413d07f0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_list = []\n",
    "cb_list.append([cstm_tb,cb_savemodel, custombn_keras_callbck()]) \n",
    "cb_list = cb_list[0]\n",
    "cb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelbn_keras.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                     loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                     metrics = [tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs1=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.6186 - categorical_accuracy: 0.8262 - val_loss: 0.4266 - val_categorical_accuracy: 0.8663\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3411 - categorical_accuracy: 0.9007 - val_loss: 0.3290 - val_categorical_accuracy: 0.9080\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2834 - categorical_accuracy: 0.9152 - val_loss: 0.2924 - val_categorical_accuracy: 0.9187\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2716 - categorical_accuracy: 0.9193 - val_loss: 0.2992 - val_categorical_accuracy: 0.9117\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2340 - categorical_accuracy: 0.9297 - val_loss: 0.2533 - val_categorical_accuracy: 0.9273\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2227 - categorical_accuracy: 0.9328 - val_loss: 0.2239 - val_categorical_accuracy: 0.9343\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2161 - categorical_accuracy: 0.9407 - val_loss: 0.2280 - val_categorical_accuracy: 0.9337\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.2106 - categorical_accuracy: 0.9397 - val_loss: 0.2172 - val_categorical_accuracy: 0.9363\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1945 - categorical_accuracy: 0.9398 - val_loss: 0.2083 - val_categorical_accuracy: 0.9410\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2023 - categorical_accuracy: 0.9387 - val_loss: 0.2067 - val_categorical_accuracy: 0.9417\n"
     ]
    }
   ],
   "source": [
    "custombn_keras_history1 =  modelbn_keras.fit(train_dataset.take(100), epochs=epochs1, verbose=1, \n",
    "                                           callbacks=cb_list, validation_data=valid_dataset.take(50), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 2ms/step - loss: 0.2069 - categorical_accuracy: 0.9371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20693755950667186, 0.9371]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelbn_keras.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "del modelbn_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
